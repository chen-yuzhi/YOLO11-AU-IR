# Ultralytics YOLO ğŸš€, AGPL-3.0 license
"""
Check a model's accuracy on a test or val split of a dataset.

Usage:
    $ yolo mode=val model=yolov8n.pt data=coco8.yaml imgsz=640

Usage - formats:
    $ yolo mode=val model=yolov8n.pt                 # PyTorch
                          yolov8n.torchscript        # TorchScript
                          yolov8n.onnx               # ONNX Runtime or OpenCV DNN with dnn=True
                          yolov8n_openvino_model     # OpenVINO
                          yolov8n.engine             # TensorRT
                          yolov8n.mlpackage          # CoreML (macOS-only)
                          yolov8n_saved_model        # TensorFlow SavedModel
                          yolov8n.pb                 # TensorFlow GraphDef
                          yolov8n.tflite             # TensorFlow Lite
                          yolov8n_edgetpu.tflite     # TensorFlow Edge TPU
                          yolov8n_paddle_model       # PaddlePaddle
                          yolov8n.mnn                # MNN
                          yolov8n_ncnn_model         # NCNN
"""

import json  # ç”¨äºå¤„ç† JSON æ–‡ä»¶
import time  # æä¾›æ—¶é—´ç›¸å…³å·¥å…·
from pathlib import Path  # ç”¨äºæ–‡ä»¶è·¯å¾„æ“ä½œ

import numpy as np  # æ•°å€¼è®¡ç®—åº“
import torch  # PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶

# å¯¼å…¥ YOLO æ¡†æ¶ä¸­çš„å·¥å…·æ¨¡å—
from ultralytics.cfg import get_cfg, get_save_dir
from ultralytics.data.utils import check_cls_dataset, check_det_dataset
from ultralytics.nn.autobackend import AutoBackend
from ultralytics.utils import LOGGER, TQDM, callbacks, colorstr, emojis
from ultralytics.utils.checks import check_imgsz
from ultralytics.utils.ops import Profile
from ultralytics.utils.torch_utils import de_parallel, select_device, smart_inference_mode


class BaseValidator:
    """
    BaseValidator.

    ä¸€ä¸ªç”¨äºåˆ›å»ºéªŒè¯å™¨çš„åŸºç±»ã€‚

    Attributes:
        args (SimpleNamespace): éªŒè¯å™¨çš„é…ç½®å‚æ•°ã€‚
        dataloader (DataLoader): ç”¨äºéªŒè¯çš„æ•°æ®åŠ è½½å™¨ã€‚
        pbar (tqdm): éªŒè¯è¿‡ç¨‹ä¸­çš„è¿›åº¦æ¡ã€‚
        model (nn.Module): ç”¨äºéªŒè¯çš„æ¨¡å‹ã€‚
        data (dict): æ•°æ®é›†ç›¸å…³çš„å­—å…¸ã€‚
        device (torch.device): éªŒè¯è¿‡ç¨‹ä¸­ä½¿ç”¨çš„è®¾å¤‡ã€‚
        batch_i (int): å½“å‰æ‰¹æ¬¡çš„ç´¢å¼•ã€‚
        training (bool): æ¨¡å‹æ˜¯å¦å¤„äºè®­ç»ƒæ¨¡å¼ã€‚
        names (dict): ç±»åˆ«åç§°ã€‚
        seen: éªŒè¯è¿‡ç¨‹ä¸­å·²å¤„ç†çš„å›¾åƒæ•°ã€‚
        stats: ç”¨äºå­˜å‚¨éªŒè¯ç»Ÿè®¡æ•°æ®çš„å ä½ç¬¦ã€‚
        confusion_matrix: æ··æ·†çŸ©é˜µå ä½ç¬¦ã€‚
        nc: ç±»åˆ«æ•°ã€‚
        iouv (torch.Tensor): IoU é˜ˆå€¼ï¼Œä» 0.50 åˆ° 0.95ï¼Œæ¯æ¬¡é€’å¢ 0.05ã€‚
        jdict (dict): ç”¨äºå­˜å‚¨ JSON æ ¼å¼çš„éªŒè¯ç»“æœã€‚
        speed (dict): è®°å½•éªŒè¯è¿‡ç¨‹ä¸­æ¯ä¸ªé˜¶æ®µçš„è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰ã€‚
        save_dir (Path): ä¿å­˜ç»“æœçš„ç›®å½•ã€‚
        plots (dict): ç”¨äºå­˜å‚¨å¯è§†åŒ–çš„ç»˜å›¾æ•°æ®ã€‚
        callbacks (dict): å­˜å‚¨å„ç§å›è°ƒå‡½æ•°ã€‚
    """

    def __init__(self, dataloader=None, save_dir=None, pbar=None, args=None, _callbacks=None):
        """
        åˆå§‹åŒ–ä¸€ä¸ª BaseValidator å®ä¾‹ã€‚

        Args:
            dataloader (torch.utils.data.DataLoader): ç”¨äºéªŒè¯çš„æ•°æ®åŠ è½½å™¨ã€‚
            save_dir (Path, optional): ä¿å­˜éªŒè¯ç»“æœçš„ç›®å½•ã€‚
            pbar (tqdm.tqdm): ç”¨äºæ˜¾ç¤ºéªŒè¯è¿›åº¦çš„è¿›åº¦æ¡ã€‚
            args (SimpleNamespace): éªŒè¯å™¨çš„é…ç½®å‚æ•°ã€‚
            _callbacks (dict): å­˜å‚¨å„ç§å›è°ƒå‡½æ•°çš„å­—å…¸ã€‚
        """
        self.args = get_cfg(overrides=args)  # è§£æå¹¶åŠ è½½éªŒè¯é…ç½®
        self.dataloader = dataloader  # è®¾ç½®éªŒè¯æ•°æ®åŠ è½½å™¨
        self.pbar = pbar  # åˆå§‹åŒ–è¿›åº¦æ¡
        self.stride = None  # æ¨¡å‹æ­¥å¹…å ä½ç¬¦
        self.data = None  # æ•°æ®é›†ä¿¡æ¯å ä½ç¬¦
        self.device = None  # è®¾å¤‡å ä½ç¬¦
        self.batch_i = None  # å½“å‰æ‰¹æ¬¡ç´¢å¼•å ä½ç¬¦
        self.training = True  # åˆå§‹çŠ¶æ€ä¸ºè®­ç»ƒæ¨¡å¼
        self.names = None  # ç±»åˆ«åç§°å ä½ç¬¦
        self.seen = None  # å·²éªŒè¯çš„å›¾åƒæ•°
        self.stats = None  # ç»Ÿè®¡æ•°æ®å ä½ç¬¦
        self.confusion_matrix = None  # æ··æ·†çŸ©é˜µå ä½ç¬¦
        self.nc = None  # ç±»åˆ«æ•°é‡
        self.iouv = None  # IoU é˜ˆå€¼
        self.jdict = None  # JSON éªŒè¯ç»“æœå ä½ç¬¦
        self.speed = {  # åˆå§‹åŒ–é€Ÿåº¦ç»Ÿè®¡
            "preprocess": 0.0,  # é¢„å¤„ç†æ—¶é—´
            "inference": 0.0,  # æ¨ç†æ—¶é—´
            "loss": 0.0,  # æŸå¤±è®¡ç®—æ—¶é—´
            "postprocess": 0.0,  # åå¤„ç†æ—¶é—´
        }

        # è®¾ç½®ä¿å­˜ç›®å½•
        self.save_dir = save_dir or get_save_dir(self.args)  # è·å–æˆ–åˆ›å»ºä¿å­˜ç›®å½•
        (self.save_dir / "labels" if self.args.save_txt else self.save_dir).mkdir(parents=True, exist_ok=True)  # åˆ›å»ºå¿…è¦å­ç›®å½•
        if self.args.conf is None:
            self.args.conf = 0.001  # é»˜è®¤ç½®ä¿¡åº¦é˜ˆå€¼ä¸º 0.001
        self.args.imgsz = check_imgsz(self.args.imgsz, max_dim=1)  # æ£€æŸ¥å¹¶è®¾ç½®è¾“å…¥å›¾åƒå°ºå¯¸

        # åˆå§‹åŒ–ç»˜å›¾å’Œå›è°ƒ
        self.plots = {}  # ç»˜å›¾å­˜å‚¨å­—å…¸
        self.callbacks = _callbacks or callbacks.get_default_callbacks()  # è®¾ç½®é»˜è®¤å›è°ƒ

    @smart_inference_mode()
    def __call__(self, trainer=None, model=None):
        """
        æ‰§è¡ŒéªŒè¯è¿‡ç¨‹ï¼Œåœ¨æ•°æ®åŠ è½½å™¨ä¸Šè¿è¡Œæ¨ç†å¹¶è®¡ç®—æ€§èƒ½æŒ‡æ ‡ã€‚

        Args:
            trainer: å¦‚æœæ¨¡å‹å¤„äºè®­ç»ƒæ¨¡å¼ï¼Œåˆ™ä¼ å…¥è®­ç»ƒå™¨å®ä¾‹ã€‚
            model: å¦‚æœéªŒè¯æœªå¤„äºè®­ç»ƒæ¨¡å¼ï¼Œåˆ™ä¼ å…¥å¾…éªŒè¯çš„æ¨¡å‹ã€‚

        Returns:
            è®­ç»ƒæ¨¡å¼ä¸‹è¿”å›æ€§èƒ½æŒ‡æ ‡å­—å…¸ï¼Œæµ‹è¯•æ¨¡å¼ä¸‹è¿”å›æœ€ç»ˆæ€§èƒ½ç»Ÿè®¡ã€‚
        """

        self.training = trainer is not None  # åˆ¤æ–­æ˜¯å¦å¤„äºè®­ç»ƒæ¨¡å¼
        augment = self.args.augment and (not self.training)  # æ•°æ®å¢å¼ºä»…åœ¨éè®­ç»ƒæ¨¡å¼ä¸‹å¯ç”¨
        if self.training:
            # å¦‚æœå¤„äºè®­ç»ƒæ¨¡å¼ï¼Œä»è®­ç»ƒå™¨ä¸­è·å–è®¾å¤‡å’Œæ•°æ®é›†ä¿¡æ¯
            self.device = trainer.device
            self.data = trainer.data
            self.args.half = self.device.type != "cpu" and trainer.amp  # æ˜¯å¦ä½¿ç”¨åŠç²¾åº¦ï¼ˆAMP æ¨¡å¼ï¼‰
            model = trainer.ema.ema or trainer.model  # ä½¿ç”¨ EMA æ¨¡å‹æˆ–åŸå§‹æ¨¡å‹
            model = model.half() if self.args.half else model.float()  # æ¨¡å‹åˆ‡æ¢åˆ°åŠç²¾åº¦æˆ–å…¨ç²¾åº¦
            self.loss = torch.zeros_like(trainer.loss_items, device=trainer.device)  # åˆå§‹åŒ–æŸå¤±ä¸º 0
            # å¦‚æœå³å°†ç»“æŸè®­ç»ƒï¼Œå¯ç”¨ç»˜å›¾
            self.args.plots &= trainer.stopper.possible_stop or (trainer.epoch == trainer.epochs - 1)
            model.eval()  # åˆ‡æ¢æ¨¡å‹åˆ°éªŒè¯æ¨¡å¼
        else:
            # éè®­ç»ƒæ¨¡å¼ä¸‹åŠ è½½æ¨¡å‹
            if str(self.args.model).endswith(".yaml"):  # å¦‚æœæŒ‡å®šçš„æ˜¯æœªè®­ç»ƒçš„æ¨¡å‹é…ç½®
                LOGGER.warning("WARNING âš ï¸ validating an untrained model YAML will result in 0 mAP.")
            callbacks.add_integration_callbacks(self)  # æ·»åŠ é›†æˆå›è°ƒ
            model = AutoBackend(  # åŠ è½½åç«¯æ”¯æŒçš„æ¨¡å‹
                weights=model or self.args.model,  # æ¨¡å‹æƒé‡
                device=select_device(self.args.device, self.args.batch),  # é€‰æ‹©è®¾å¤‡
                dnn=self.args.dnn,  # æ˜¯å¦ä½¿ç”¨ DNN æ¨ç†
                data=self.args.data,  # æ•°æ®é›†è·¯å¾„
                fp16=self.args.half,  # æ˜¯å¦ä½¿ç”¨åŠç²¾åº¦æ¨ç†
            )
            self.device = model.device  # æ›´æ–°è®¾å¤‡ä¿¡æ¯
            self.args.half = model.fp16  # æ›´æ–°ç²¾åº¦ä¿¡æ¯
            stride, pt, jit, engine = model.stride, model.pt, model.jit, model.engine  # è·å–æ¨¡å‹å±æ€§
            imgsz = check_imgsz(self.args.imgsz, stride=stride)  # æ£€æŸ¥å›¾åƒå°ºå¯¸æ˜¯å¦ä¸æ¨¡å‹æ­¥å¹…å¯¹é½
            if engine:  # å¦‚æœä½¿ç”¨ TensorRT æ¨ç†å¼•æ“
                self.args.batch = model.batch_size  # æ›´æ–°æ‰¹é‡å¤§å°
            elif not pt and not jit:  # é PyTorch æ¨¡å‹
                self.args.batch = model.metadata.get("batch", 1)  # é»˜è®¤æ‰¹é‡å¤§å°ä¸º 1
                LOGGER.info(f"Setting batch={self.args.batch} input of shape ({self.args.batch}, 3, {imgsz}, {imgsz})")

            # æ ¹æ®ä»»åŠ¡ç±»å‹åŠ è½½æ•°æ®é›†
            if str(self.args.data).split(".")[-1] in {"yaml", "yml"}:  # æ£€æµ‹ä»»åŠ¡æ•°æ®é›†
                self.data = check_det_dataset(self.args.data)
            elif self.args.task == "classify":  # åˆ†ç±»ä»»åŠ¡æ•°æ®é›†
                self.data = check_cls_dataset(self.args.data, split=self.args.split)
            else:  # æœªçŸ¥ä»»åŠ¡ç±»å‹æŠ›å‡ºå¼‚å¸¸
                raise FileNotFoundError(emojis(f"Dataset '{self.args.data}' for task={self.args.task} not found âŒ"))

            if self.device.type in {"cpu", "mps"}:  # å¦‚æœæ˜¯ CPU æˆ– Apple MPS è®¾å¤‡
                self.args.workers = 0  # æ•°æ®åŠ è½½çº¿ç¨‹æ•°è®¾ä¸º 0ï¼ŒåŠ é€Ÿæ¨ç†
            if not pt:  # é PyTorch æ¨¡å‹ç¦ç”¨çŸ©å½¢æ¨ç†
                self.args.rect = False
            self.stride = model.stride  # ä¿å­˜æ¨¡å‹æ­¥å¹…
            self.dataloader = self.dataloader or self.get_dataloader(self.data.get(self.args.split), self.args.batch)  # è·å–æ•°æ®åŠ è½½å™¨

            model.eval()  # åˆ‡æ¢æ¨¡å‹åˆ°éªŒè¯æ¨¡å¼
            model.warmup(imgsz=(1 if pt else self.args.batch, 3, imgsz, imgsz))  # æ¨¡å‹é¢„çƒ­

        self.run_callbacks("on_val_start")  # è§¦å‘éªŒè¯å¼€å§‹å›è°ƒäº‹ä»¶
        dt = (
            Profile(device=self.device),  # åˆå§‹åŒ–é˜¶æ®µè®¡æ—¶å™¨
            Profile(device=self.device),
            Profile(device=self.device),
            Profile(device=self.device),
        )
        bar = TQDM(self.dataloader, desc=self.get_desc(), total=len(self.dataloader))  # åˆ›å»ºè¿›åº¦æ¡
        self.init_metrics(de_parallel(model))  # åˆå§‹åŒ–æ€§èƒ½æŒ‡æ ‡
        self.jdict = []  # æ¸…ç©º JSON éªŒè¯ç»“æœ
        for batch_i, batch in enumerate(bar):  # éå†æ¯ä¸ªæ‰¹æ¬¡çš„æ•°æ®
            self.run_callbacks("on_val_batch_start")  # è§¦å‘æ‰¹æ¬¡å¼€å§‹å›è°ƒ
            self.batch_i = batch_i  # æ›´æ–°å½“å‰æ‰¹æ¬¡ç´¢å¼•

            # é¢„å¤„ç†
            with dt[0]:
                batch = self.preprocess(batch)

            # æ¨ç†
            with dt[1]:
                preds = model(batch["img"], augment=augment)

            # æŸå¤±è®¡ç®—ï¼ˆä»…è®­ç»ƒæ¨¡å¼ä¸‹ï¼‰
            with dt[2]:
                if self.training:
                    self.loss += model.loss(batch, preds)[1]

            # åå¤„ç†
            with dt[3]:
                preds = self.postprocess(preds)

            # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
            self.update_metrics(preds, batch)
            if self.args.plots and batch_i < 3:  # è‹¥å¯ç”¨ç»˜å›¾ä¸”å½“å‰æ‰¹æ¬¡æ•°å°äº 3
                self.plot_val_samples(batch, batch_i)  # ç»˜åˆ¶éªŒè¯æ ·æœ¬
                self.plot_predictions(batch, preds, batch_i)  # ç»˜åˆ¶é¢„æµ‹ç»“æœ

            self.run_callbacks("on_val_batch_end")  # è§¦å‘æ‰¹æ¬¡ç»“æŸå›è°ƒ

        stats = self.get_stats()  # è·å–æ€§èƒ½ç»Ÿè®¡
        self.check_stats(stats)  # æ£€æŸ¥æ€§èƒ½ç»Ÿè®¡
        self.speed = dict(zip(self.speed.keys(), (x.t / len(self.dataloader.dataset) * 1e3 for x in dt)))  # è®¡ç®—é˜¶æ®µè€—æ—¶
        self.finalize_metrics()  # å®ŒæˆæŒ‡æ ‡è®¡ç®—
        self.print_results()  # æ‰“å°ç»“æœ
        self.run_callbacks("on_val_end")  # è§¦å‘éªŒè¯ç»“æŸå›è°ƒ

        if self.training:  # è‹¥å¤„äºè®­ç»ƒæ¨¡å¼
            model.float()  # å°†æ¨¡å‹åˆ‡æ¢å›å…¨ç²¾åº¦
            results = {**stats, **trainer.label_loss_items(self.loss.cpu() / len(self.dataloader), prefix="val")}  # æ±‡æ€»ç»“æœ
            return {k: round(float(v), 5) for k, v in results.items()}  # è¿”å›ç»“æœï¼Œä¿ç•™ 5 ä½å°æ•°
        else:
            # æ‰“å°é€Ÿåº¦ä¿¡æ¯
            LOGGER.info(
                "Speed: {:.1f}ms preprocess, {:.1f}ms inference, {:.1f}ms loss, {:.1f}ms postprocess per image".format(
                    *tuple(self.speed.values())
                )
            )
            LOGGER.info(f'FPS:{(1000/sum(self.speed.values())):.2f}')
            # ä¿å­˜ JSON æ ¼å¼çš„é¢„æµ‹ç»“æœ
            if self.args.save_json and self.jdict:
                with open(str(self.save_dir / "predictions.json"), "w") as f:
                    LOGGER.info(f"Saving {f.name}...")
                    json.dump(self.jdict, f)  # ä¿å­˜ JSON æ–‡ä»¶
                stats = self.eval_json(stats)  # æ›´æ–°ç»Ÿè®¡ç»“æœ
            if self.args.plots or self.args.save_json:
                LOGGER.info(f"Results saved to {colorstr('bold', self.save_dir)}")  # æ‰“å°ä¿å­˜è·¯å¾„ä¿¡æ¯
            return stats  # è¿”å›æ€§èƒ½ç»Ÿè®¡

    def match_predictions(self, pred_classes, true_classes, iou, use_scipy=False):
        """
        æ ¹æ® IoU å’Œç±»åˆ«åŒ¹é…é¢„æµ‹ä¸çœŸå®ç›®æ ‡ã€‚

        Args:
            pred_classes (torch.Tensor): é¢„æµ‹ç±»åˆ«ç´¢å¼•ï¼Œå½¢çŠ¶ä¸º (N, )ã€‚
            true_classes (torch.Tensor): çœŸå®ç±»åˆ«ç´¢å¼•ï¼Œå½¢çŠ¶ä¸º (M, )ã€‚
            iou (torch.Tensor): N x M çš„ IoU çŸ©é˜µï¼Œè¡¨ç¤ºé¢„æµ‹æ¡†å’ŒçœŸå®æ¡†çš„ IoUã€‚
            use_scipy (bool): æ˜¯å¦ä½¿ç”¨ scipy è¿›è¡ŒåŒ¹é…ï¼ˆç²¾åº¦æ›´é«˜ï¼‰ã€‚

        Returns:
            torch.Tensor: åŒ¹é…ç»“æœçŸ©é˜µï¼Œå½¢çŠ¶ä¸º (N, 10)ï¼Œè¡¨ç¤ºå¯¹æ¯ä¸ª IoU é˜ˆå€¼çš„åŒ¹é…æƒ…å†µã€‚
        """
        correct = np.zeros((pred_classes.shape[0], self.iouv.shape[0])).astype(bool)  # åˆå§‹åŒ–åŒ¹é…ç»“æœçŸ©é˜µ
        correct_class = true_classes[:, None] == pred_classes  # æ£€æŸ¥ç±»åˆ«æ˜¯å¦åŒ¹é…
        iou = iou * correct_class  # å°†ç±»åˆ«ä¸åŒ¹é…çš„ IoU ç½®ä¸º 0
        iou = iou.cpu().numpy()  # è½¬ä¸º numpy æ•°ç»„ä»¥åŠ é€Ÿå¤„ç†
        for i, threshold in enumerate(self.iouv.cpu().tolist()):  # éå†æ¯ä¸ª IoU é˜ˆå€¼
            if use_scipy:  # ä½¿ç”¨ scipy è¿›è¡Œä¼˜åŒ–åŒ¹é…
                import scipy  # å±€éƒ¨å¯¼å…¥ scipy
                cost_matrix = iou * (iou >= threshold)  # æ„å»ºä»£ä»·çŸ©é˜µï¼Œä»…ä¿ç•™æ»¡è¶³é˜ˆå€¼çš„ IoU
                if cost_matrix.any():  # å¦‚æœæœ‰æ»¡è¶³æ¡ä»¶çš„åŒ¹é…
                    labels_idx, detections_idx = scipy.optimize.linear_sum_assignment(cost_matrix, maximize=True)
                    valid = cost_matrix[labels_idx, detections_idx] > 0  # æ£€æŸ¥æ˜¯å¦æœ‰æ•ˆ
                    if valid.any():  # è‹¥æœ‰æœ‰æ•ˆåŒ¹é…
                        correct[detections_idx[valid], i] = True
            else:  # ä½¿ç”¨ numpy è¿›è¡ŒåŒ¹é…
                matches = np.nonzero(iou >= threshold)  # æ‰¾åˆ°æ»¡è¶³ IoU é˜ˆå€¼çš„åŒ¹é…
                matches = np.array(matches).T
                if matches.shape[0]:  # å¦‚æœå­˜åœ¨åŒ¹é…
                    if matches.shape[0] > 1:  # å¤šå¯¹å¤šåŒ¹é…
                        matches = matches[iou[matches[:, 0], matches[:, 1]].argsort()[::-1]]  # æŒ‰ IoU æ’åº
                        matches = matches[np.unique(matches[:, 1], return_index=True)[1]]  # æ¯ä¸ªçœŸå®ç›®æ ‡åªåŒ¹é…ä¸€æ¬¡
                        matches = matches[np.unique(matches[:, 0], return_index=True)[1]]  # æ¯ä¸ªé¢„æµ‹æ¡†åªåŒ¹é…ä¸€æ¬¡
                    correct[matches[:, 1].astype(int), i] = True  # æ›´æ–°åŒ¹é…ç»“æœ
        return torch.tensor(correct, dtype=torch.bool, device=pred_classes.device)  # è½¬ä¸º Tensor è¿”å›


    def add_callback(self, event: str, callback):
        """Appends the given callback."""
        self.callbacks[event].append(callback)

    def run_callbacks(self, event: str):
        """Runs all callbacks associated with a specified event."""
        for callback in self.callbacks.get(event, []):
            callback(self)

    def get_dataloader(self, dataset_path, batch_size):
        """Get data loader from dataset path and batch size."""
        raise NotImplementedError("get_dataloader function not implemented for this validator")

    def build_dataset(self, img_path):
        """Build dataset."""
        raise NotImplementedError("build_dataset function not implemented in validator")

    def preprocess(self, batch):
        """Preprocesses an input batch."""
        return batch

    def postprocess(self, preds):
        """Preprocesses the predictions."""
        return preds

    def init_metrics(self, model):
        """Initialize performance metrics for the YOLO model."""
        pass

    def update_metrics(self, preds, batch):
        """Updates metrics based on predictions and batch."""
        pass

    def finalize_metrics(self, *args, **kwargs):
        """Finalizes and returns all metrics."""
        pass

    def get_stats(self):
        """Returns statistics about the model's performance."""
        return {}

    def check_stats(self, stats):
        """Checks statistics."""
        pass

    def print_results(self):
        """Prints the results of the model's predictions."""
        pass

    def get_desc(self):
        """Get description of the YOLO model."""
        pass

    @property
    def metric_keys(self):
        """Returns the metric keys used in YOLO training/validation."""
        return []

    def on_plot(self, name, data=None):
        """Registers plots (e.g. to be consumed in callbacks)."""
        self.plots[Path(name)] = {"data": data, "timestamp": time.time()}

    # TODO: may need to put these following functions into callback
    def plot_val_samples(self, batch, ni):
        """Plots validation samples during training."""
        pass

    def plot_predictions(self, batch, preds, ni):
        """Plots YOLO model predictions on batch images."""
        pass

    def pred_to_json(self, preds, batch):
        """Convert predictions to JSON format."""
        pass

    def eval_json(self, stats):
        """Evaluate and return JSON format of prediction statistics."""
        pass
