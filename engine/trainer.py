# Ultralytics YOLO ğŸš€, AGPL-3.0 license
"""
Train a model on a dataset.

Usage:
    $ yolo mode=train model=yolov8n.pt data=coco8.yaml imgsz=640 epochs=100 batch=16
"""

import gc  # ç”¨äºåƒåœ¾å›æ”¶ï¼Œé‡Šæ”¾ä¸å†ä½¿ç”¨çš„å†…å­˜
import math  # æä¾›æ•°å­¦è®¡ç®—å·¥å…·
import os  # æä¾›æ“ä½œç³»ç»Ÿç›¸å…³åŠŸèƒ½ï¼Œå¦‚æ–‡ä»¶è·¯å¾„æ“ä½œ
import subprocess  # ç”¨äºè¿è¡Œå­è¿›ç¨‹
import time  # æä¾›æ—¶é—´ç›¸å…³çš„åŠŸèƒ½
import warnings  # ç”¨äºç®¡ç†è­¦å‘Šä¿¡æ¯
from copy import copy, deepcopy  # ç”¨äºå¯¹è±¡çš„æµ…æ‹·è´å’Œæ·±æ‹·è´
from datetime import datetime, timedelta  # æä¾›æ—¥æœŸå’Œæ—¶é—´æ“ä½œå·¥å…·
from pathlib import Path  # ç”¨äºæ›´æ–¹ä¾¿åœ°æ“ä½œæ–‡ä»¶è·¯å¾„

# ç§‘å­¦è®¡ç®—ä¸æ·±åº¦å­¦ä¹ åº“
import numpy as np  # æä¾›é«˜æ•ˆçš„å¤šç»´æ•°ç»„æ“ä½œ
import torch  # PyTorch çš„æ ¸å¿ƒæ¨¡å—ï¼Œç”¨äºæ·±åº¦å­¦ä¹ 
from torch import distributed as dist  # ç”¨äºåˆ†å¸ƒå¼è®­ç»ƒ
from torch import nn, optim  # `nn` ç”¨äºæ„å»ºç¥ç»ç½‘ç»œï¼Œ`optim` æä¾›ä¼˜åŒ–å™¨

# å¯¼å…¥ YOLO æ¡†æ¶çš„æ ¸å¿ƒå·¥å…·
from ultralytics.cfg import get_cfg, get_save_dir  # è·å–é…ç½®å’Œä¿å­˜è·¯å¾„
from ultralytics.data.utils import check_cls_dataset, check_det_dataset  # æ•°æ®é›†æ£€æŸ¥å·¥å…·
from ultralytics.nn.tasks import attempt_load_one_weight, attempt_load_weights  # åŠ è½½æ¨¡å‹æƒé‡
from ultralytics.utils import (  # å®ç”¨å·¥å…·æ¨¡å—
    DEFAULT_CFG,  # é»˜è®¤é…ç½®
    LOCAL_RANK,  # æœ¬åœ°è¿›ç¨‹çš„ GPU ID
    LOGGER,  # æ—¥å¿—è®°å½•å·¥å…·
    RANK,  # è¿›ç¨‹çš„å…¨å±€ ID
    TQDM,  # è¿›åº¦æ¡å·¥å…·
    __version__,  # ç‰ˆæœ¬å·
    callbacks,  # å›è°ƒç®¡ç†
    clean_url,  # å¤„ç† URL çš„å·¥å…·
    colorstr,  # æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼Œæ”¯æŒé¢œè‰²è¾“å‡º
    emojis,  # è¡¨æƒ…ç¬¦å·æ”¯æŒ
    yaml_save,  # å°†æ•°æ®ä¿å­˜ä¸º YAML æ–‡ä»¶
)
from ultralytics.utils.autobatch import check_train_batch_size  # åŠ¨æ€è°ƒæ•´é€‚åˆçš„æ‰¹é‡å¤§å°
from ultralytics.utils.checks import (  # ç”¨äºè®­ç»ƒå‰æ£€æŸ¥å’Œé…ç½®
    check_amp,  # æ£€æŸ¥æ˜¯å¦å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
    check_file,  # æ£€æŸ¥æ–‡ä»¶è·¯å¾„
    check_imgsz,  # éªŒè¯è¾“å…¥å›¾åƒå¤§å°
    check_model_file_from_stem,  # éªŒè¯æ¨¡å‹æ–‡ä»¶å
    print_args,  # æ‰“å°è®­ç»ƒå‚æ•°
)
from ultralytics.utils.dist import ddp_cleanup, generate_ddp_command  # åˆ†å¸ƒå¼è®­ç»ƒç›¸å…³å·¥å…·
from ultralytics.utils.files import get_latest_run  # è·å–æœ€æ–°çš„è¿è¡Œè®°å½•
from ultralytics.utils.torch_utils import (  # PyTorch å®ç”¨å·¥å…·
    TORCH_2_4,  # æ£€æŸ¥ PyTorch ç‰ˆæœ¬
    EarlyStopping,  # æå‰åœæ­¢è®­ç»ƒçš„æœºåˆ¶
    ModelEMA,  # æ¨¡å‹çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡
    autocast,  # è‡ªåŠ¨æ··åˆç²¾åº¦
    convert_optimizer_state_dict_to_fp16,  # å°†ä¼˜åŒ–å™¨çŠ¶æ€è½¬ä¸º FP16 ç²¾åº¦
    init_seeds,  # åˆå§‹åŒ–éšæœºç§å­
    one_cycle,  # ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦å™¨
    select_device,  # é€‰æ‹©è®¡ç®—è®¾å¤‡ï¼ˆCPU/GPUï¼‰
    strip_optimizer,  # æ¸…ç†ä¼˜åŒ–å™¨çŠ¶æ€ä»¥å‡å°æ¨¡å‹ä½“ç§¯
    torch_distributed_zero_first,  # ç¡®ä¿åˆ†å¸ƒå¼è®­ç»ƒçš„ç¬¬ä¸€ä¸ªè¿›ç¨‹ä¼˜å…ˆè¿è¡Œ
)


class BaseTrainer:
    """
    A base class for creating trainers.

    Attributes:
        args (SimpleNamespace): é…ç½®å‚æ•°ï¼Œä¾‹å¦‚è®­ç»ƒè¶…å‚æ•°ã€è®¾å¤‡ç­‰ã€‚
        validator (BaseValidator): éªŒè¯å™¨å®ä¾‹ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚
        model (nn.Module): æ¨¡å‹å®ä¾‹ï¼Œå®šä¹‰äº†è¦è®­ç»ƒçš„ç¥ç»ç½‘ç»œã€‚
        callbacks (defaultdict): å›è°ƒå‡½æ•°å­—å…¸ï¼Œç”¨äºåœ¨ç‰¹å®šè®­ç»ƒäº‹ä»¶ä¸­è§¦å‘å‡½æ•°ã€‚
        save_dir (Path): ç»“æœä¿å­˜çš„ç›®å½•è·¯å¾„ã€‚
        wdir (Path): æƒé‡ä¿å­˜çš„ç›®å½•è·¯å¾„ã€‚
        last (Path): æœ€è¿‘ä¸€æ¬¡ä¿å­˜çš„æ£€æŸ¥ç‚¹è·¯å¾„ã€‚
        best (Path): ä¿å­˜æ€§èƒ½æœ€ä½³çš„æ£€æŸ¥ç‚¹è·¯å¾„ã€‚
        save_period (int): è®¾ç½®æ¯éš”å¤šå°‘ä¸ª epoch ä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹ï¼ˆè‹¥ <1 åˆ™ç¦ç”¨ï¼‰ã€‚
        batch_size (int): è®­ç»ƒæ—¶çš„æ‰¹é‡å¤§å°ã€‚
        epochs (int): è®­ç»ƒçš„æ€» epoch æ•°ã€‚
        start_epoch (int): è®­ç»ƒçš„èµ·å§‹ epochã€‚
        device (torch.device): æŒ‡å®šä½¿ç”¨çš„è®¾å¤‡ï¼ˆCPU æˆ– GPUï¼‰ã€‚
        amp (bool): æ˜¯å¦å¯ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ (AMP)ã€‚
        scaler (amp.GradScaler): AMP çš„æ¢¯åº¦ç¼©æ”¾å™¨å®ä¾‹ã€‚
        data (str): æ•°æ®é›†è·¯å¾„æˆ–æè¿°æ–‡ä»¶ã€‚
        trainset (torch.utils.data.Dataset): è®­ç»ƒæ•°æ®é›†å®ä¾‹ã€‚
        testset (torch.utils.data.Dataset): æµ‹è¯•æ•°æ®é›†å®ä¾‹ã€‚
        ema (nn.Module): æ¨¡å‹çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡ (EMA) å®ä¾‹ã€‚
        resume (bool): æ˜¯å¦ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒã€‚
        lf (nn.Module): æŸå¤±å‡½æ•°å®ä¾‹ã€‚
        scheduler (torch.optim.lr_scheduler._LRScheduler): å­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚
        best_fitness (float): å½“å‰è®­ç»ƒè¿‡ç¨‹ä¸­è¾¾åˆ°çš„æœ€ä½³æ€§èƒ½æŒ‡æ ‡ã€‚
        fitness (float): å½“å‰ epoch çš„æ€§èƒ½æŒ‡æ ‡ã€‚
        loss (float): å½“å‰ epoch çš„æŸå¤±å€¼ã€‚
        tloss (float): ç´¯è®¡æŸå¤±å€¼ã€‚
        loss_names (list): æŸå¤±é¡¹çš„åç§°åˆ—è¡¨ã€‚
        csv (Path): ä¿å­˜ç»“æœçš„ CSV æ–‡ä»¶è·¯å¾„ã€‚
    """

    def __init__(self, cfg=DEFAULT_CFG, overrides=None, _callbacks=None):
        """
        Initializes the BaseTrainer class.

        Args:
            cfg (str, optional): é…ç½®æ–‡ä»¶è·¯å¾„æˆ–é»˜è®¤é…ç½®ã€‚é»˜è®¤ä¸º DEFAULT_CFGã€‚
            overrides (dict, optional): é…ç½®çš„è¦†ç›–å‚æ•°ã€‚é»˜è®¤ä¸º Noneã€‚
        """
        self.args = get_cfg(cfg, overrides)  # åŠ è½½å¹¶è§£æè®­ç»ƒé…ç½®
        self.check_resume(overrides)  # æ£€æŸ¥æ˜¯å¦ä»æ£€æŸ¥ç‚¹æ¢å¤
        self.device = select_device(self.args.device, self.args.batch)  # é€‰æ‹©è®­ç»ƒè®¾å¤‡ï¼ˆCPU æˆ– GPUï¼‰
        self.validator = None  # éªŒè¯å™¨åˆå§‹åŒ–ä¸º None
        self.metrics = None  # å­˜å‚¨è¯„ä¼°æŒ‡æ ‡
        self.plots = {}  # ç”¨äºå­˜å‚¨ç»˜å›¾æ•°æ®
        init_seeds(self.args.seed + 1 + RANK, deterministic=self.args.deterministic)  # åˆå§‹åŒ–éšæœºç§å­

        # è®¾ç½®ä¿å­˜ç›®å½•
        self.save_dir = get_save_dir(self.args)  # ç¡®å®šä¿å­˜è·¯å¾„
        self.args.name = self.save_dir.name  # æ›´æ–°åç§°ä»¥ä¾¿äºæ—¥å¿—è®°å½•
        self.wdir = self.save_dir / "weights"  # æƒé‡ä¿å­˜çš„å­ç›®å½•
        if RANK in {-1, 0}:  # ä»…ä¸»è¿›ç¨‹åˆ›å»ºä¿å­˜è·¯å¾„
            self.wdir.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºç›®å½•
            self.args.save_dir = str(self.save_dir)  # æ›´æ–°é…ç½®ä¸­çš„ä¿å­˜è·¯å¾„
            yaml_save(self.save_dir / "args.yaml", vars(self.args))  # å°†å‚æ•°ä¿å­˜ä¸º YAML æ–‡ä»¶
        self.last, self.best = self.wdir / "last.pt", self.wdir / "best.pt"  # è®¾ç½®æ£€æŸ¥ç‚¹è·¯å¾„
        self.save_period = self.args.save_period  # ä¿å­˜å‘¨æœŸè®¾ç½®

        # åˆå§‹åŒ–è®­ç»ƒç›¸å…³å‚æ•°
        self.batch_size = self.args.batch  # æ‰¹é‡å¤§å°
        self.epochs = self.args.epochs or 100  # æ€» epoch æ•°ï¼Œè‹¥ä¸º None åˆ™é»˜è®¤ 100
        self.start_epoch = 0  # èµ·å§‹ epoch ä¸º 0
        if RANK == -1:  # ä»…åœ¨å• GPU æˆ– CPU ç¯å¢ƒä¸‹æ‰“å°å‚æ•°
            print_args(vars(self.args))

        # è®¾å¤‡ç›¸å…³è®¾ç½®
        if self.device.type in {"cpu", "mps"}:  # è‹¥è®¾å¤‡ä¸º CPU æˆ– MPS
            self.args.workers = 0  # å°†æ•°æ®åŠ è½½å™¨çš„ worker æ•°é‡è®¾ç½®ä¸º 0ï¼Œä»¥æå‡æ•ˆç‡

        # æ¨¡å‹å’Œæ•°æ®é›†è®¾ç½®
        self.model = check_model_file_from_stem(self.args.model)  # åŠ è½½æ¨¡å‹æ–‡ä»¶è·¯å¾„
        with torch_distributed_zero_first(LOCAL_RANK):  # åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­é¿å…å¤šæ¬¡ä¸‹è½½æ•°æ®é›†
            self.trainset, self.testset = self.get_dataset()  # åŠ è½½è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†
        self.ema = None  # åˆå§‹åŒ– EMA ä¸º None

        # åˆå§‹åŒ–ä¼˜åŒ–å·¥å…·
        self.lf = None  # æŸå¤±å‡½æ•°
        self.scheduler = None  # å­¦ä¹ ç‡è°ƒåº¦å™¨

        # è®°å½•è®­ç»ƒè¿‡ç¨‹çš„æŒ‡æ ‡
        self.best_fitness = None  # æœ€ä½³æŒ‡æ ‡
        self.fitness = None  # å½“å‰æŒ‡æ ‡
        self.loss = None  # å½“å‰æŸå¤±
        self.tloss = None  # ç´¯è®¡æŸå¤±
        self.loss_names = ["Loss"]  # æŸå¤±é¡¹çš„åç§°
        self.csv = self.save_dir / "results.csv"  # ç»“æœ CSV æ–‡ä»¶è·¯å¾„
        self.plot_idx = [0, 1, 2]  # ç»˜å›¾ç´¢å¼•

        # é›†æˆæ”¯æŒ
        self.hub_session = None  # é›†æˆä¼šè¯åˆå§‹åŒ–ä¸º None

        # å›è°ƒå‡½æ•°è®¾ç½®
        self.callbacks = _callbacks or callbacks.get_default_callbacks()  # è·å–é»˜è®¤å›è°ƒ
        if RANK in {-1, 0}:  # ä¸»è¿›ç¨‹æ·»åŠ é›†æˆå›è°ƒ
            callbacks.add_integration_callbacks(self)


    def add_callback(self, event: str, callback):
        """Appends the given callback."""
        # ä¸ºç‰¹å®šäº‹ä»¶æ·»åŠ æ–°çš„å›è°ƒå‡½æ•°
        self.callbacks[event].append(callback)

    def set_callback(self, event: str, callback):
        """Overrides the existing callbacks with the given callback."""
        # è¦†ç›–ç‰¹å®šäº‹ä»¶çš„æ‰€æœ‰å›è°ƒå‡½æ•°ï¼Œåªä¿ç•™æ–°çš„å›è°ƒå‡½æ•°
        self.callbacks[event] = [callback]

    def run_callbacks(self, event: str):
        """Run all existing callbacks associated with a particular event."""
        # è¿è¡ŒæŒ‡å®šäº‹ä»¶çš„æ‰€æœ‰å›è°ƒå‡½æ•°
        for callback in self.callbacks.get(event, []):
            callback(self)

    def train(self):
        """Allow device='', device=None on Multi-GPU systems to default to device=0."""
        # ç¡®å®šåˆ†å¸ƒå¼è®­ç»ƒçš„è®¾å¤‡æ•°é‡
        if isinstance(self.args.device, str) and len(self.args.device):  # è®¾å¤‡å‚æ•°ä¸ºå­—ç¬¦ä¸²ï¼ˆå¦‚ '0,1,2'ï¼‰
            world_size = len(self.args.device.split(","))
        elif isinstance(self.args.device, (tuple, list)):  # è®¾å¤‡å‚æ•°ä¸ºåˆ—è¡¨ï¼ˆå¦‚ [0, 1]ï¼‰
            world_size = len(self.args.device)
        elif self.args.device in {"cpu", "mps"}:  # è®¾å¤‡ä¸º CPU æˆ– Apple çš„ MPS
            world_size = 0
        elif torch.cuda.is_available():  # GPU å¯ç”¨ï¼Œè®¾å¤‡é»˜è®¤ä¸º 1
            world_size = 1
        else:  # è®¾å¤‡æœªæŒ‡å®šä¸”æ²¡æœ‰ GPU
            world_size = 0

        # å¦‚æœä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒ (DDP)
        if world_size > 1 and "LOCAL_RANK" not in os.environ:
            # ç¡®ä¿ç‰¹å®šå‚æ•°åœ¨ DDP ä¸­çš„è®¾ç½®
            if self.args.rect:
                LOGGER.warning("WARNING âš ï¸ 'rect=True' is incompatible with Multi-GPU training, setting 'rect=False'")
                self.args.rect = False
            if self.args.batch < 1.0:
                LOGGER.warning(
                    "WARNING âš ï¸ 'batch<1' for AutoBatch is incompatible with Multi-GPU training, setting "
                    "default 'batch=16'"
                )
                self.args.batch = 16

            # ç”Ÿæˆ DDP å‘½ä»¤å¹¶è¿è¡Œ
            cmd, file = generate_ddp_command(world_size, self)
            try:
                LOGGER.info(f'{colorstr("DDP:")} debug command {" ".join(cmd)}')
                subprocess.run(cmd, check=True)  # æ‰§è¡Œåˆ†å¸ƒå¼è®­ç»ƒå‘½ä»¤
            except Exception as e:
                raise e
            finally:
                ddp_cleanup(self, str(file))  # æ¸…ç†åˆ†å¸ƒå¼è¿›ç¨‹
        else:
            # è‹¥éåˆ†å¸ƒå¼è®­ç»ƒï¼Œç›´æ¥å¼€å§‹è®­ç»ƒ
            self._do_train(world_size)

    def _setup_scheduler(self):
        """Initialize training learning rate scheduler."""
        # åˆå§‹åŒ–å­¦ä¹ ç‡è°ƒåº¦å™¨
        if self.args.cos_lr:  # ä½™å¼¦è°ƒåº¦
            self.lf = one_cycle(1, self.args.lrf, self.epochs)  # ç”Ÿæˆä½™å¼¦è°ƒåº¦å™¨å‡½æ•°
        else:  # çº¿æ€§è°ƒåº¦
            self.lf = lambda x: max(1 - x / self.epochs, 0) * (1.0 - self.args.lrf) + self.args.lrf
        # å°†è°ƒåº¦å™¨ç»‘å®šåˆ°ä¼˜åŒ–å™¨
        self.scheduler = optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda=self.lf)

    def _setup_ddp(self, world_size):
        """Initializes and sets the DistributedDataParallel parameters for training."""
        # è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒå‚æ•°
        torch.cuda.set_device(RANK)  # ä¸ºå½“å‰è¿›ç¨‹åˆ†é… GPU
        self.device = torch.device("cuda", RANK)  # ç¡®å®šå½“å‰è®¾å¤‡ä¸º CUDA
        os.environ["TORCH_NCCL_BLOCKING_WAIT"] = "1"  # å¼ºåˆ¶è¶…æ—¶ç­‰å¾…
        # åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒ
        dist.init_process_group(
            backend="nccl" if dist.is_nccl_available() else "gloo",  # NCCL æˆ– Gloo åç«¯
            timeout=timedelta(seconds=10800),  # è¶…æ—¶æ—¶é—´ 3 å°æ—¶
            rank=RANK,  # å½“å‰è¿›ç¨‹çš„ rank
            world_size=world_size,  # æ€»è¿›ç¨‹æ•°
        )

    def _setup_train(self, world_size):
        """Builds dataloaders and optimizer on correct rank process."""
        # åˆå§‹åŒ–è®­ç»ƒæ‰€éœ€çš„ dataloader å’Œä¼˜åŒ–å™¨
        self.run_callbacks("on_pretrain_routine_start")  # è§¦å‘ "on_pretrain_routine_start" å›è°ƒäº‹ä»¶
        ckpt = self.setup_model()  # åŠ è½½æˆ–åˆ›å»ºæ¨¡å‹
        self.model = self.model.to(self.device)  # å°†æ¨¡å‹ç§»è‡³æŒ‡å®šè®¾å¤‡
        self.set_model_attributes()  # è®¾ç½®æ¨¡å‹çš„å±æ€§

        # å†»ç»“ç‰¹å®šå±‚
        freeze_list = (
            self.args.freeze
            if isinstance(self.args.freeze, list)
            else range(self.args.freeze)
            if isinstance(self.args.freeze, int)
            else []
        )  # æ ¹æ®é…ç½®å†³å®šå†»ç»“å“ªäº›å±‚
        always_freeze_names = [".dfl"]  # é»˜è®¤å†»ç»“çš„å±‚ï¼ˆå¦‚ DFLï¼‰
        freeze_layer_names = [f"model.{x}." for x in freeze_list] + always_freeze_names
        for k, v in self.model.named_parameters():
            if any(x in k for x in freeze_layer_names):  # åˆ¤æ–­å½“å‰å‚æ•°æ˜¯å¦éœ€è¦å†»ç»“
                LOGGER.info(f"Freezing layer '{k}'")
                v.requires_grad = False  # å†»ç»“å‚æ•°
            elif not v.requires_grad and v.dtype.is_floating_point:  # ç¡®ä¿å†»ç»“çš„æµ®ç‚¹å‚æ•°å¯ä»¥æ¢¯åº¦æ›´æ–°
                LOGGER.info(
                    f"WARNING âš ï¸ setting 'requires_grad=True' for frozen layer '{k}'. "
                    "See ultralytics.engine.trainer for customization of frozen layers."
                )
                v.requires_grad = True

        # æ£€æŸ¥ AMPï¼ˆè‡ªåŠ¨æ··åˆç²¾åº¦ï¼‰
        self.amp = torch.tensor(self.args.amp).to(self.device)  # åˆå§‹åŒ– AMP æ ‡å¿—
        if self.amp and RANK in {-1, 0}:  # è‹¥å¯ç”¨ AMPï¼Œä¸”å½“å‰ä¸ºä¸»è¿›ç¨‹
            callbacks_backup = callbacks.default_callbacks.copy()  # å¤‡ä»½å›è°ƒ
            self.amp = torch.tensor(check_amp(self.model), device=self.device)  # æ£€æŸ¥ AMP æ”¯æŒ
            callbacks.default_callbacks = callbacks_backup  # æ¢å¤å›è°ƒ
        if RANK > -1 and world_size > 1:  # è‹¥ä¸ºåˆ†å¸ƒå¼è®­ç»ƒ
            dist.broadcast(self.amp, src=0)  # å¹¿æ’­ AMP è®¾ç½®è‡³æ‰€æœ‰è¿›ç¨‹
        self.amp = bool(self.amp)  # è½¬ä¸ºå¸ƒå°”å€¼
        self.scaler = (
            torch.amp.GradScaler("cuda", enabled=self.amp) if TORCH_2_4 else torch.cuda.amp.GradScaler(enabled=self.amp)
        )  # åˆå§‹åŒ–æ¢¯åº¦ç¼©æ”¾å™¨
        if world_size > 1:  # è‹¥åˆ†å¸ƒå¼è®­ç»ƒï¼Œå°è£…æ¨¡å‹ä¸º DDP æ¨¡å¼
            self.model = nn.parallel.DistributedDataParallel(self.model, device_ids=[RANK], find_unused_parameters=True)

        # éªŒè¯è¾“å…¥å›¾åƒå°ºå¯¸
        gs = max(int(self.model.stride.max() if hasattr(self.model, "stride") else 32), 32)  # ç¡®å®šæœ€å¤§æ­¥å¹…
        self.args.imgsz = check_imgsz(self.args.imgsz, stride=gs, floor=gs, max_dim=1)  # éªŒè¯å›¾åƒå°ºå¯¸
        self.stride = gs  # ä¿å­˜æ­¥å¹…

        # è°ƒæ•´æ‰¹é‡å¤§å°
        if self.batch_size < 1 and RANK == -1:  # å• GPU ä¸‹ä¼°ç®—æœ€ä½³æ‰¹é‡å¤§å°
            self.args.batch = self.batch_size = self.auto_batch()

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        batch_size = self.batch_size // max(world_size, 1)  # æ ¹æ®è®¾å¤‡æ•°é‡è°ƒæ•´æ‰¹é‡å¤§å°
        self.train_loader = self.get_dataloader(self.trainset, batch_size=batch_size, rank=LOCAL_RANK, mode="train")  # è®­ç»ƒåŠ è½½å™¨
        if RANK in {-1, 0}:  # ä¸»è¿›ç¨‹åˆ›å»ºéªŒè¯åŠ è½½å™¨
            self.test_loader = self.get_dataloader(
                self.testset, batch_size=batch_size * 2, rank=-1, mode="val"  # éªŒè¯åŠ è½½å™¨ï¼Œæ‰¹é‡å¤§å°ä¸ºè®­ç»ƒçš„ä¸¤å€
            )
            self.validator = self.get_validator()  # åˆå§‹åŒ–éªŒè¯å™¨
            metric_keys = self.validator.metrics.keys + self.label_loss_items(prefix="val")  # è·å–éªŒè¯æŒ‡æ ‡
            self.metrics = dict(zip(metric_keys, [0] * len(metric_keys)))  # åˆå§‹åŒ–éªŒè¯æŒ‡æ ‡ä¸º 0
            self.ema = ModelEMA(self.model)  # åˆå§‹åŒ– EMA æ¨¡å‹
            if self.args.plots:
                self.plot_training_labels()  # ç»˜åˆ¶è®­ç»ƒæ ‡ç­¾åˆ†å¸ƒ

        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        self.accumulate = max(round(self.args.nbs / self.batch_size), 1)  # ç´¯ç§¯æ¢¯åº¦æ›´æ–°çš„æ¬¡æ•°
        weight_decay = self.args.weight_decay * self.batch_size * self.accumulate / self.args.nbs  # è°ƒæ•´æƒé‡è¡°å‡
        iterations = math.ceil(len(self.train_loader.dataset) / max(self.batch_size, self.args.nbs)) * self.epochs  # è¿­ä»£æ€»æ¬¡æ•°
        self.optimizer = self.build_optimizer(
            model=self.model,
            name=self.args.optimizer,
            lr=self.args.lr0,
            momentum=self.args.momentum,
            decay=weight_decay,
            iterations=iterations,
        )  # åˆ›å»ºä¼˜åŒ–å™¨

        # åˆå§‹åŒ–å­¦ä¹ ç‡è°ƒåº¦å™¨
        self._setup_scheduler()
        self.stopper, self.stop = EarlyStopping(patience=self.args.patience), False  # æå‰åœæ­¢æœºåˆ¶
        self.resume_training(ckpt)  # æ£€æŸ¥æ˜¯å¦æ¢å¤è®­ç»ƒ
        self.scheduler.last_epoch = self.start_epoch - 1  # è®¾ç½®è°ƒåº¦å™¨çš„èµ·å§‹ epoch
        self.run_callbacks("on_pretrain_routine_end")  # è§¦å‘ "on_pretrain_routine_end" å›è°ƒäº‹ä»¶
    def _do_train(self, world_size=1):
        """Train completed, evaluate and plot if specified by arguments."""
        # è®­ç»ƒè¿‡ç¨‹çš„å®é™…æ‰§è¡Œ
        if world_size > 1:  # è‹¥ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒ
            self._setup_ddp(world_size)  # è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒ
        self._setup_train(world_size)  # è®¾ç½®è®­ç»ƒè¿‡ç¨‹ï¼ˆå¦‚ä¼˜åŒ–å™¨ã€æ•°æ®åŠ è½½å™¨ç­‰ï¼‰

        nb = len(self.train_loader)  # è®­ç»ƒé›†çš„æ‰¹æ¬¡æ•°
        nw = max(round(self.args.warmup_epochs * nb), 100) if self.args.warmup_epochs > 0 else -1  # é¢„çƒ­è¿­ä»£æ¬¡æ•°
        last_opt_step = -1  # ä¸Šæ¬¡ä¼˜åŒ–çš„æ­¥éª¤
        self.epoch_time = None  # åˆå§‹åŒ– epoch è®¡æ—¶
        self.epoch_time_start = time.time()  # è®°å½• epoch å¼€å§‹æ—¶é—´
        self.train_time_start = time.time()  # è®°å½•è®­ç»ƒå¼€å§‹æ—¶é—´
        self.run_callbacks("on_train_start")  # è§¦å‘ "on_train_start" å›è°ƒäº‹ä»¶
        LOGGER.info(
            f'Image sizes {self.args.imgsz} train, {self.args.imgsz} val\n'
            f'Using {self.train_loader.num_workers * (world_size or 1)} dataloader workers\n'
            f"Logging results to {colorstr('bold', self.save_dir)}\n"
            f'Starting training for ' + (f"{self.args.time} hours..." if self.args.time else f"{self.epochs} epochs...")
        )
        if self.args.close_mosaic:
            base_idx = (self.epochs - self.args.close_mosaic) * nb  # å…³é—­ mosaic å¢å¼ºæ—¶çš„ç´¢å¼•
            self.plot_idx.extend([base_idx, base_idx + 1, base_idx + 2])  # ç»˜å›¾çš„ç´¢å¼•
        epoch = self.start_epoch  # è®¾ç½® epoch èµ·å§‹å€¼
        self.optimizer.zero_grad()  # æ¸…ç©ºä¼˜åŒ–å™¨çš„æ¢¯åº¦
        while True:
            self.epoch = epoch  # å½“å‰ epoch
            self.run_callbacks("on_train_epoch_start")  # è§¦å‘ "on_train_epoch_start" å›è°ƒäº‹ä»¶
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")  # å¿½ç•¥æŸäº›è­¦å‘Š
                self.scheduler.step()  # å­¦ä¹ ç‡æ›´æ–°

            self.model.train()  # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
            if RANK != -1:
                self.train_loader.sampler.set_epoch(epoch)  # è®¾ç½®æ•°æ®åŠ è½½å™¨çš„ epoch
            pbar = enumerate(self.train_loader)  # æšä¸¾è®­ç»ƒæ•°æ®åŠ è½½å™¨
            if epoch == (self.epochs - self.args.close_mosaic):  # è‹¥è¾¾åˆ°å…³é—­ mosaic å¢å¼ºçš„æ¡ä»¶
                self._close_dataloader_mosaic()  # å…³é—­ mosaic å¢å¼º
                self.train_loader.reset()  # é‡ç½®æ•°æ®åŠ è½½å™¨

            if RANK in {-1, 0}:  # ä»…åœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºè¿›åº¦æ¡
                LOGGER.info(self.progress_string())  # æ‰“å°è®­ç»ƒè¿›åº¦
                pbar = TQDM(enumerate(self.train_loader), total=nb)  # ä½¿ç”¨ TQDM æ˜¾ç¤ºè¿›åº¦æ¡
            self.tloss = None  # åˆå§‹åŒ–å½“å‰ epoch çš„æ€»æŸå¤±
            for i, batch in pbar:
                self.run_callbacks("on_train_batch_start")  # è§¦å‘ "on_train_batch_start" å›è°ƒäº‹ä»¶
                # Warmupï¼šå­¦ä¹ ç‡é¢„çƒ­
                ni = i + nb * epoch  # å½“å‰è¿­ä»£çš„æ­¥æ•°
                if ni <= nw:
                    xi = [0, nw]  # é¢„çƒ­åŒºé—´
                    self.accumulate = max(1, int(np.interp(ni, xi, [1, self.args.nbs / self.batch_size]).round()))  # è°ƒæ•´ç´¯ç§¯æ­¥æ•°
                    for j, x in enumerate(self.optimizer.param_groups):  # æ›´æ–°å­¦ä¹ ç‡
                        x["lr"] = np.interp(ni, xi, [self.args.warmup_bias_lr if j == 0 else 0.0, x["initial_lr"] * self.lf(epoch)])
                        if "momentum" in x:
                            x["momentum"] = np.interp(ni, xi, [self.args.warmup_momentum, self.args.momentum])

                # å‰å‘ä¼ æ’­
                with autocast(self.amp):  # è‡ªåŠ¨æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
                    batch = self.preprocess_batch(batch)  # æ•°æ®é¢„å¤„ç†
                    self.loss, self.loss_items = self.model(batch)  # è®¡ç®—æŸå¤±
                    if RANK != -1:  # åˆ†å¸ƒå¼è®­ç»ƒä¸­æ”¾å¤§æŸå¤±
                        self.loss *= world_size
                    self.tloss = (
                        (self.tloss * i + self.loss_items) / (i + 1) if self.tloss is not None else self.loss_items
                    )  # ç´¯è®¡æŸå¤±

                # åå‘ä¼ æ’­
                self.scaler.scale(self.loss).backward()  # æ¢¯åº¦ç¼©æ”¾åçš„åå‘ä¼ æ’­

                # ä¼˜åŒ–
                if ni - last_opt_step >= self.accumulate:  # æ ¹æ®ç´¯ç§¯æ­¥æ•°è¿›è¡Œä¼˜åŒ–
                    self.optimizer_step()
                    last_opt_step = ni

                    # æ ¹æ®æ—¶é—´åœæ­¢è®­ç»ƒ
                    if self.args.time:
                        self.stop = (time.time() - self.train_time_start) > (self.args.time * 3600)  # è¶…è¿‡æŒ‡å®šæ—¶é—´åˆ™åœæ­¢è®­ç»ƒ
                        if RANK != -1:  # è‹¥æ˜¯åˆ†å¸ƒå¼è®­ç»ƒï¼Œå¹¿æ’­åœæ­¢ä¿¡å·
                            broadcast_list = [self.stop if RANK == 0 else None]
                            dist.broadcast_object_list(broadcast_list, 0)  # å¹¿æ’­åœæ­¢ä¿¡å·
                            self.stop = broadcast_list[0]
                        if self.stop:  # å¦‚æœè¶…è¿‡è®­ç»ƒæ—¶é—´ï¼Œåˆ™åœæ­¢è®­ç»ƒ
                            break

                # æ—¥å¿—è®°å½•
                if RANK in {-1, 0}:  # ä¸»è¿›ç¨‹è®°å½•æ—¥å¿—
                    loss_length = self.tloss.shape[0] if len(self.tloss.shape) else 1
                    pbar.set_description(
                        ("%11s" * 2 + "%11.4g" * (2 + loss_length))
                        % (
                            f"{epoch + 1}/{self.epochs}",
                            f"{self._get_memory():.3g}G",  # æ˜¾ç¤º GPU å†…å­˜ä½¿ç”¨æƒ…å†µ
                            *(self.tloss if loss_length > 1 else torch.unsqueeze(self.tloss, 0)),  # æŸå¤±
                            batch["cls"].shape[0],  # å½“å‰æ‰¹æ¬¡çš„å¤§å°
                            batch["img"].shape[-1],  # å½“å‰å›¾åƒå°ºå¯¸
                        )
                    )
                    self.run_callbacks("on_batch_end")  # è§¦å‘ "on_batch_end" å›è°ƒäº‹ä»¶
                    if self.args.plots and ni in self.plot_idx:
                        self.plot_training_samples(batch, ni)  # ç»˜åˆ¶è®­ç»ƒæ ·æœ¬

                self.run_callbacks("on_train_batch_end")  # è§¦å‘ "on_train_batch_end" å›è°ƒäº‹ä»¶

            self.lr = {f"lr/pg{ir}": x["lr"] for ir, x in enumerate(self.optimizer.param_groups)}  # è®°å½•æ¯ä¸ªå‚æ•°ç»„çš„å­¦ä¹ ç‡
            self.run_callbacks("on_train_epoch_end")  # è§¦å‘ "on_train_epoch_end" å›è°ƒäº‹ä»¶
            if RANK in {-1, 0}:  # ä¸»è¿›ç¨‹è¿›è¡Œæ¨¡å‹éªŒè¯ä¸ä¿å­˜
                final_epoch = epoch + 1 >= self.epochs
                self.ema.update_attr(self.model, include=["yaml", "nc", "args", "names", "stride", "class_weights"])

                # éªŒè¯
                if self.args.val or final_epoch or self.stopper.possible_stop or self.stop:
                    self.metrics, self.fitness = self.validate()  # éªŒè¯æ¨¡å‹æ€§èƒ½
                self.save_metrics(metrics={**self.label_loss_items(self.tloss), **self.metrics, **self.lr})  # ä¿å­˜æŒ‡æ ‡
                self.stop |= self.stopper(epoch + 1, self.fitness) or final_epoch  # åˆ¤æ–­æ˜¯å¦æå‰åœæ­¢
                if self.args.time:
                    self.stop |= (time.time() - self.train_time_start) > (self.args.time * 3600)  # æ ¹æ®æ—¶é—´åœæ­¢

                # ä¿å­˜æ¨¡å‹
                if self.args.save or final_epoch:
                    self.save_model()
                    self.run_callbacks("on_model_save")  # è§¦å‘ "on_model_save" å›è°ƒäº‹ä»¶

            # å­¦ä¹ ç‡è°ƒåº¦
            t = time.time()
            self.epoch_time = t - self.epoch_time_start  # å½“å‰ epoch çš„æ—¶é—´
            self.epoch_time_start = t  # æ›´æ–° epoch å¼€å§‹æ—¶é—´
            if self.args.time:
                mean_epoch_time = (t - self.train_time_start) / (epoch - self.start_epoch + 1)  # ä¼°ç®—å¹³å‡ epoch æ—¶é—´
                self.epochs = self.args.epochs = math.ceil(self.args.time * 3600 / mean_epoch_time)  # è°ƒæ•´è®­ç»ƒæ€» epoch
                self._setup_scheduler()  # é‡æ–°åˆå§‹åŒ–å­¦ä¹ ç‡è°ƒåº¦å™¨
                self.scheduler.last_epoch = self.epoch  # ç¡®ä¿ä¸è°ƒæ•´ epoch
                self.stop |= epoch >= self.epochs  # åˆ¤æ–­æ˜¯å¦è¶…è¿‡æœ€å¤§è®­ç»ƒ epoch
            self.run_callbacks("on_fit_epoch_end")  # è§¦å‘ "on_fit_epoch_end" å›è°ƒäº‹ä»¶
            self._clear_memory()  # æ¸…ç†å†…å­˜

            # æå‰åœæ­¢
            if RANK != -1:  # åˆ†å¸ƒå¼è®­ç»ƒ
                broadcast_list = [self.stop if RANK == 0 else None]
                dist.broadcast_object_list(broadcast_list, 0)  # å¹¿æ’­åœæ­¢ä¿¡å·
                self.stop = broadcast_list[0]
            if self.stop:  # å¦‚æœè¾¾åˆ°åœæ­¢æ¡ä»¶ï¼Œåˆ™é€€å‡º
                break
            epoch += 1  # å¢åŠ  epoch

        if RANK in {-1, 0}:  # ç»“æŸè®­ç»ƒåè¿›è¡Œæœ€ç»ˆè¯„ä¼°
            seconds = time.time() - self.train_time_start
            LOGGER.info(f"\n{epoch - self.start_epoch + 1} epochs completed in {seconds / 3600:.3f} hours.")
            self.final_eval()  # è¿›è¡Œæœ€ç»ˆè¯„ä¼°
            if self.args.plots:
                self.plot_metrics()  # ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŒ‡æ ‡å›¾
            self.run_callbacks("on_train_end")  # è§¦å‘ "on_train_end" å›è°ƒäº‹ä»¶
        self._clear_memory()  # æ¸…ç†å†…å­˜
        self.run_callbacks("teardown")  # è§¦å‘ "teardown" å›è°ƒäº‹ä»¶

    def auto_batch(self, max_num_obj=0):
        """Get batch size by calculating memory occupation of model."""
        # åŠ¨æ€è°ƒæ•´æ‰¹é‡å¤§å°ä»¥é€‚åº”æ¨¡å‹çš„å†…å­˜å ç”¨
        return check_train_batch_size(
            model=self.model,
            imgsz=self.args.imgsz,
            amp=self.amp,
            batch=self.batch_size,
            max_num_obj=max_num_obj,
        )  # è¿”å›æ¨èçš„æ‰¹é‡å¤§å°

    def _get_memory(self):
        """Get accelerator memory utilization in GB."""
        # è·å–è®¾å¤‡çš„å†…å­˜ä½¿ç”¨æƒ…å†µ
        if self.device.type == "mps":
            memory = torch.mps.driver_allocated_memory()
        elif self.device.type == "cpu":
            memory = 0
        else:
            memory = torch.cuda.memory_reserved()
        return memory / 1e9  # è½¬æ¢ä¸º GB

    def _clear_memory(self):
        """Clear accelerator memory on different platforms."""
        # æ¸…ç†æ˜¾å­˜æˆ–å†…å­˜
        gc.collect()  # åƒåœ¾å›æ”¶
        if self.device.type == "mps":
            torch.mps.empty_cache()  # æ¸…ç† MPS æ˜¾å­˜
        elif self.device.type == "cpu":
            return  # å¦‚æœæ˜¯ CPUï¼Œä¸åšä»»ä½•æ“ä½œ
        else:
            torch.cuda.empty_cache()  # æ¸…ç† CUDA æ˜¾å­˜



    def read_results_csv(self):
        """Read results.csv into a dict using pandas."""
        # ä½¿ç”¨ pandas è¯»å–è®­ç»ƒç»“æœ CSV æ–‡ä»¶å¹¶è¿”å›ä¸ºå­—å…¸æ ¼å¼
        import pandas as pd  # å»¶è¿Ÿå¯¼å…¥ä»¥æé«˜åˆå§‹åŒ–é€Ÿåº¦
        return pd.read_csv(self.csv).to_dict(orient="list")  # è¯»å–å¹¶è½¬æ¢ä¸ºå­—å…¸ï¼ŒæŒ‰åˆ—å­˜å‚¨

    def save_model(self):
        """Save model training checkpoints with additional metadata."""
        # ä¿å­˜è®­ç»ƒæ¨¡å‹çš„æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œå¹¶é™„åŠ é¢å¤–çš„å…ƒæ•°æ®
        import io  # ç”¨äºåœ¨å†…å­˜ä¸­æ“ä½œå­—èŠ‚æµ

        # å°†æ£€æŸ¥ç‚¹æ•°æ®åºåˆ—åŒ–åˆ°å†…å­˜ä¸­
        buffer = io.BytesIO()
        torch.save(
            {
                "epoch": self.epoch,  # å½“å‰è®­ç»ƒçš„ epoch
                "best_fitness": self.best_fitness,  # å½“å‰æœ€ä½³çš„ fitness å€¼
                "model": None,  # æ¨¡å‹ï¼Œä¿å­˜æ—¶ä¸åŒ…å«æ¨¡å‹æœ¬èº«
                "ema": deepcopy(self.ema.ema).half(),  # EMA æ¨¡å‹ï¼ŒåŠç²¾åº¦ä¿å­˜
                "updates": self.ema.updates,  # EMA æ›´æ–°æ¬¡æ•°
                "optimizer": convert_optimizer_state_dict_to_fp16(deepcopy(self.optimizer.state_dict())),  # ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œè½¬æ¢ä¸º FP16
                "train_args": vars(self.args),  # ä¿å­˜è®­ç»ƒæ—¶çš„å‚æ•°
                "train_metrics": {**self.metrics, **{"fitness": self.fitness}},  # è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŒ‡æ ‡
                "train_results": self.read_results_csv(),  # è®­ç»ƒç»“æœ
                "date": datetime.now().isoformat(),  # å½“å‰æ—¶é—´
                "version": __version__,  # å½“å‰ YOLO ç‰ˆæœ¬
                "license": "AGPL-3.0 (https://ultralytics.com/license)",  # è®¸å¯è¯
                "docs": "https://docs.ultralytics.com",  # æ–‡æ¡£é“¾æ¥
            },
            buffer,
        )
        serialized_ckpt = buffer.getvalue()  # è·å–åºåˆ—åŒ–çš„æ£€æŸ¥ç‚¹å­—èŠ‚æµ

        # ä¿å­˜æ£€æŸ¥ç‚¹æ–‡ä»¶
        self.last.write_bytes(serialized_ckpt)  # ä¿å­˜æœ€æ–°çš„æ£€æŸ¥ç‚¹
        if self.best_fitness == self.fitness:
            self.best.write_bytes(serialized_ckpt)  # è‹¥å½“å‰ fitness æ˜¯æœ€ä½³å€¼ï¼Œåˆ™ä¿å­˜æœ€ä½³æ£€æŸ¥ç‚¹
        if (self.save_period > 0) and (self.epoch % self.save_period == 0):
            (self.wdir / f"epoch{self.epoch}.pt").write_bytes(serialized_ckpt)  # æŒ‰ç…§ä¿å­˜å‘¨æœŸä¿å­˜ epoch æ£€æŸ¥ç‚¹
        # å¦‚æœè®¾ç½®äº† mosaic å¹¶ä¸”å½“å‰ epoch æ˜¯æœ€åä¸€ä¸ªè¦å…³é—­ mosaic çš„ epochï¼Œåˆ™ä¿å­˜ç›¸åº”æ£€æŸ¥ç‚¹
        # if self.args.close_mosaic and self.epoch == (self.epochs - self.args.close_mosaic - 1):
        #    (self.wdir / "last_mosaic.pt").write_bytes(serialized_ckpt)

    def get_dataset(self):
        """
        Get train, val path from data dict if it exists.

        Returns None if data format is not recognized.
        """
        # åŠ è½½æ•°æ®é›†å¹¶è¿”å›è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„è·¯å¾„
        try:
            if self.args.task == "classify":
                data = check_cls_dataset(self.args.data)  # åˆ†ç±»ä»»åŠ¡
            elif self.args.data.split(".")[-1] in {"yaml", "yml"} or self.args.task in {
                "detect",
                "segment",
                "pose",
                "obb",
            }:
                data = check_det_dataset(self.args.data)  # æ£€æµ‹ä»»åŠ¡
                if "yaml_file" in data:
                    self.args.data = data["yaml_file"]  # ç¡®ä¿æ•°æ®é›†è·¯å¾„æ˜¯ YAML æ–‡ä»¶
        except Exception as e:
            raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error âŒ {e}")) from e
        self.data = data  # å°†æ•°æ®é›†å­˜å‚¨åˆ°å®ä¾‹å˜é‡
        return data["train"], data.get("val") or data.get("test")  # è¿”å›è®­ç»ƒé›†å’ŒéªŒè¯é›†è·¯å¾„

    def setup_model(self):
        """Load/create/download model for any task."""
        # åŠ è½½ã€åˆ›å»ºæˆ–ä¸‹è½½æ¨¡å‹
        if isinstance(self.model, torch.nn.Module):  # å¦‚æœæ¨¡å‹å·²ç»æ˜¯ä¸€ä¸ª nn.Module å®ä¾‹ï¼Œåˆ™ä¸éœ€è¦é‡æ–°åŠ è½½
            return

        cfg, weights = self.model, None
        ckpt = None
        if str(self.model).endswith(".pt"):  # å¦‚æœæ¨¡å‹æ˜¯ä»¥ .pt ç»“å°¾ï¼Œåˆ™åŠ è½½æƒé‡
            weights, ckpt = attempt_load_one_weight(self.model)
            cfg = weights.yaml
        elif isinstance(self.args.pretrained, (str, Path)):  # å¦‚æœæœ‰é¢„è®­ç»ƒæƒé‡
            weights, _ = attempt_load_one_weight(self.args.pretrained)
        self.model = self.get_model(cfg=cfg, weights=weights, verbose=RANK == -1)  # åŠ è½½æ¨¡å‹
        return ckpt

    def optimizer_step(self):
        """Perform a single step of the training optimizer with gradient clipping and EMA update."""
        # æ‰§è¡Œä¼˜åŒ–å™¨çš„å•æ­¥æ›´æ–°ï¼Œå¸¦æœ‰æ¢¯åº¦è£å‰ªå’Œ EMA æ›´æ–°
        self.scaler.unscale_(self.optimizer)  # å»é™¤æ¢¯åº¦ç¼©æ”¾
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=10.0)  # æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
        self.scaler.step(self.optimizer)  # ä¼˜åŒ–å™¨æ­¥è¿›
        self.scaler.update()  # æ›´æ–°ç¼©æ”¾å™¨
        self.optimizer.zero_grad()  # æ¸…ç©ºä¼˜åŒ–å™¨çš„æ¢¯åº¦
        if self.ema:
            self.ema.update(self.model)  # æ›´æ–° EMA æ¨¡å‹

    def preprocess_batch(self, batch):
        """Allows custom preprocessing model inputs and ground truths depending on task type."""
        # æ‰§è¡Œæ‰¹é‡æ•°æ®çš„é¢„å¤„ç†
        return batch  # é»˜è®¤ä¸åšé¢„å¤„ç†ï¼Œç›´æ¥è¿”å› batch

    def validate(self):
        """
        Runs validation on test set using self.validator.

        The returned dict is expected to contain "fitness" key.
        """
        # åœ¨éªŒè¯é›†ä¸Šè¿è¡Œæ¨¡å‹éªŒè¯
        metrics = self.validator(self)  # è°ƒç”¨éªŒè¯å™¨è¿›è¡ŒéªŒè¯
        fitness = metrics.pop("fitness", -self.loss.detach().cpu().numpy())  # è·å– fitnessï¼Œè‹¥æ²¡æœ‰åˆ™ä½¿ç”¨è´ŸæŸå¤±å€¼ä½œä¸º fitness
        if not self.best_fitness or self.best_fitness < fitness:  # æ›´æ–°æœ€ä½³ fitness
            self.best_fitness = fitness
        return metrics, fitness

    def get_model(self, cfg=None, weights=None, verbose=True):
        """Get model and raise NotImplementedError for loading cfg files."""
        # è·å–æ¨¡å‹å®ä¾‹
        raise NotImplementedError("This task trainer doesn't support loading cfg files")  # è‹¥æœªå®ç°æ­¤æ–¹æ³•ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸

    def get_validator(self):
        """Returns a NotImplementedError when the get_validator function is called."""
        # è¿”å›éªŒè¯å™¨å®ä¾‹
        raise NotImplementedError("get_validator function not implemented in trainer")  # å¦‚æœæœªå®ç°æ­¤æ–¹æ³•ï¼ŒæŠ›å‡ºå¼‚å¸¸

    def get_dataloader(self, dataset_path, batch_size=16, rank=0, mode="train"):
        """Returns dataloader derived from torch.data.Dataloader."""
        # è·å–æ•°æ®åŠ è½½å™¨å®ä¾‹
        raise NotImplementedError("get_dataloader function not implemented in trainer")  # å¦‚æœæœªå®ç°æ­¤æ–¹æ³•ï¼ŒæŠ›å‡ºå¼‚å¸¸

    def build_dataset(self, img_path, mode="train", batch=None):
        """Build dataset."""
        # æ„å»ºæ•°æ®é›†å®ä¾‹
        raise NotImplementedError("build_dataset function not implemented in trainer")  # å¦‚æœæœªå®ç°æ­¤æ–¹æ³•ï¼ŒæŠ›å‡ºå¼‚å¸¸

    def label_loss_items(self, loss_items=None, prefix="train"):
        """
        Returns a loss dict with labelled training loss items tensor.

        Note:
            This is not needed for classification but necessary for segmentation & detection
        """
        # è¿”å›å¸¦æ ‡ç­¾çš„æŸå¤±é¡¹å­—å…¸
        return {"loss": loss_items} if loss_items is not None else ["loss"]

    def set_model_attributes(self):
        """To set or update model parameters before training."""
        # è®¾ç½®æˆ–æ›´æ–°æ¨¡å‹çš„å‚æ•°
        self.model.names = self.data["names"]  # è®¾ç½®æ¨¡å‹çš„ç±»åˆ«åç§°

    def build_targets(self, preds, targets):
        """Builds target tensors for training YOLO model."""
        # æ„å»ºè®­ç»ƒç›®æ ‡å¼ é‡
        pass  # æ­¤æ–¹æ³•å°šæœªå®ç°

    def progress_string(self):
        """Returns a string describing training progress."""
        # è¿”å›æè¿°è®­ç»ƒè¿›åº¦çš„å­—ç¬¦ä¸²
        return ""

    # TODO: may need to put these following functions into callback
    def plot_training_samples(self, batch, ni):
        """Plots training samples during YOLO training."""
        # ç»˜åˆ¶è®­ç»ƒæ ·æœ¬
        pass  # å°šæœªå®ç°

    def plot_training_labels(self):
        """Plots training labels for YOLO model."""
        # ç»˜åˆ¶è®­ç»ƒæ ‡ç­¾
        pass  # å°šæœªå®ç°

    def save_metrics(self, metrics):
        """ä¿å­˜è®­ç»ƒè¿‡ç¨‹ä¸­ç”Ÿæˆçš„æŒ‡æ ‡åˆ° CSV æ–‡ä»¶ã€‚"""
        # è·å–æŒ‡æ ‡çš„é”®å’Œå€¼
        keys, vals = list(metrics.keys()), list(metrics.values())
        n = len(metrics) + 2  # åŒ…æ‹¬ epoch å’Œ time ä¸¤åˆ—
        # å¦‚æœ CSV æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™æ·»åŠ è¡¨å¤´ï¼Œå¦åˆ™ä¸ºç©º
        s = "" if self.csv.exists() else (("%s," * n % tuple(["epoch", "time"] + keys)).rstrip(",") + "\n")
        t = time.time() - self.train_time_start  # è®¡ç®—å½“å‰è®­ç»ƒæ—¶é—´
        # æ‰“å¼€ CSV æ–‡ä»¶å¹¶è¿½åŠ æ•°æ®
        with open(self.csv, "a") as f:
            f.write(s + ("%.6g," * n % tuple([self.epoch + 1, t] + vals)).rstrip(",") + "\n")  # å†™å…¥ epochã€æ—¶é—´å’ŒæŒ‡æ ‡

    def plot_metrics(self):
        """å¯è§†åŒ–è®­ç»ƒæŒ‡æ ‡ï¼ˆæœªå®ç°ï¼‰ã€‚"""
        pass

    def on_plot(self, name, data=None):
        """æ³¨å†Œç»˜å›¾æ•°æ®ï¼ˆå¯ç”¨äºå›è°ƒï¼‰ã€‚"""
        path = Path(name)  # ç¡®å®šç»˜å›¾è·¯å¾„
        self.plots[path] = {"data": data, "timestamp": time.time()}  # å­˜å‚¨ç»˜å›¾æ•°æ®åŠæ—¶é—´æˆ³

    def final_eval(self):
        """æ‰§è¡Œæœ€ç»ˆçš„è¯„ä¼°å’ŒéªŒè¯æ“ä½œï¼Œé€‚ç”¨äº YOLO å¯¹è±¡æ£€æµ‹æ¨¡å‹ã€‚"""
        ckpt = {}  # ç”¨äºå­˜å‚¨æ£€æŸ¥ç‚¹æ•°æ®
        for f in self.last, self.best:  # éå†æœ€æ–°æ£€æŸ¥ç‚¹å’Œæœ€ä½³æ£€æŸ¥ç‚¹
            if f.exists():  # å¦‚æœæ–‡ä»¶å­˜åœ¨
                if f is self.last:  # å¯¹æœ€è¿‘çš„æ£€æŸ¥ç‚¹è¿›è¡Œå¤„ç†
                    ckpt = strip_optimizer(f)  # æ¸…ç†ä¼˜åŒ–å™¨çŠ¶æ€
                elif f is self.best:  # å¯¹æœ€ä½³æ£€æŸ¥ç‚¹è¿›è¡Œå¤„ç†
                    k = "train_results"  # æ›´æ–°æœ€ä½³æ£€æŸ¥ç‚¹ä¸­çš„è®­ç»ƒç»“æœ
                    strip_optimizer(f, updates={k: ckpt[k]} if k in ckpt else None)  # å¤„ç†æœ€ä½³æ£€æŸ¥ç‚¹æ–‡ä»¶
                    LOGGER.info(f"\nValidating {f}...")  # æ‰“å°éªŒè¯ä¿¡æ¯
                    self.validator.args.plots = self.args.plots  # è®¾ç½®éªŒè¯å™¨æ˜¯å¦ç”Ÿæˆç»˜å›¾
                    self.metrics = self.validator(model=f)  # ä½¿ç”¨éªŒè¯å™¨å¯¹æ¨¡å‹è¿›è¡ŒéªŒè¯
                    self.metrics.pop("fitness", None)  # ç§»é™¤ fitness æŒ‡æ ‡
                    self.run_callbacks("on_fit_epoch_end")  # è§¦å‘ fit_epoch_end å›è°ƒäº‹ä»¶

    def check_resume(self, overrides):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒï¼Œå¹¶æ›´æ–°ç›¸åº”çš„å‚æ•°ã€‚"""
        resume = self.args.resume  # æ£€æŸ¥æ˜¯å¦æŒ‡å®šäº†æ¢å¤è®­ç»ƒçš„æ ‡å¿—
        if resume:
            try:
                # ç¡®å®šæ£€æŸ¥ç‚¹è·¯å¾„æ˜¯å¦å­˜åœ¨
                exists = isinstance(resume, (str, Path)) and Path(resume).exists()
                last = Path(check_file(resume) if exists else get_latest_run())  # è·å–æœ€æ–°è¿è¡Œçš„æ£€æŸ¥ç‚¹

                # æ£€æŸ¥æ•°æ®é›†çš„ YAML æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™é‡æ–°ä¸‹è½½
                ckpt_args = attempt_load_weights(last).args
                if not Path(ckpt_args["data"]).exists():
                    ckpt_args["data"] = self.args.data  # æ›´æ–°ä¸ºå½“å‰æ•°æ®é›†è·¯å¾„

                resume = True  # æ ‡è®°ä¸ºæ¢å¤è®­ç»ƒ
                self.args = get_cfg(ckpt_args)  # æ›´æ–°è®­ç»ƒé…ç½®
                self.args.model = self.args.resume = str(last)  # æ›´æ–°æ¨¡å‹è·¯å¾„å’Œæ¢å¤è·¯å¾„
                # æ ¹æ® overrides å‚æ•°è¦†ç›–æŸäº›è®­ç»ƒå‚æ•°
                for k in ("imgsz", "batch", "device", "close_mosaic"):
                    if k in overrides:
                        setattr(self.args, k, overrides[k])  # åŠ¨æ€æ›´æ–°å‚æ•°

            except Exception as e:
                # å¦‚æœæ¢å¤æ£€æŸ¥ç‚¹å¤±è´¥ï¼ŒæŠ›å‡ºé”™è¯¯æç¤º
                raise FileNotFoundError(
                    "Resume checkpoint not found. Please pass a valid checkpoint to resume from, "
                    "i.e. 'yolo train resume model=path/to/last.pt'"
                ) from e
        self.resume = resume  # æ›´æ–°æ¢å¤æ ‡å¿—

    def resume_training(self, ckpt):
        """ä»æŒ‡å®šçš„æ£€æŸ¥ç‚¹æ¢å¤ YOLO æ¨¡å‹çš„è®­ç»ƒã€‚"""
        if ckpt is None or not self.resume:  # å¦‚æœæ²¡æœ‰æŒ‡å®šæ£€æŸ¥ç‚¹æˆ–ä¸éœ€è¦æ¢å¤è®­ç»ƒ
            return
        best_fitness = 0.0  # åˆå§‹åŒ–æœ€ä½³ fitness å€¼
        start_epoch = ckpt.get("epoch", -1) + 1  # è·å–ä»å“ªä¸€è½®å¼€å§‹æ¢å¤è®­ç»ƒ
        if ckpt.get("optimizer", None) is not None:
            self.optimizer.load_state_dict(ckpt["optimizer"])  # æ¢å¤ä¼˜åŒ–å™¨çŠ¶æ€
            best_fitness = ckpt["best_fitness"]  # æ¢å¤æœ€ä½³ fitness
        if self.ema and ckpt.get("ema"):  # å¦‚æœå¯ç”¨äº† EMAï¼Œåˆ™æ¢å¤å…¶çŠ¶æ€
            self.ema.ema.load_state_dict(ckpt["ema"].float().state_dict())  # åŠ è½½ EMA æ¨¡å‹
            self.ema.updates = ckpt["updates"]  # æ›´æ–° EMA æ›´æ–°æ¬¡æ•°
        assert start_epoch > 0, (  # ç¡®ä¿è®­ç»ƒæ²¡æœ‰å®Œå…¨ç»“æŸ
            f"{self.args.model} training to {self.epochs} epochs is finished, nothing to resume.\n"
            f"Start a new training without resuming, i.e. 'yolo train model={self.args.model}'"
        )
        LOGGER.info(f"Resuming training {self.args.model} from epoch {start_epoch + 1} to {self.epochs} total epochs")
        if self.epochs < start_epoch:  # å¦‚æœç›®æ ‡è®­ç»ƒè½®æ•°å°äºæ¢å¤çš„èµ·å§‹è½®æ•°
            LOGGER.info(
                f"{self.model} has been trained for {ckpt['epoch']} epochs. Fine-tuning for {self.epochs} more epochs."
            )
            self.epochs += ckpt["epoch"]  # å¢åŠ ç›®æ ‡è½®æ•°
        self.best_fitness = best_fitness  # æ›´æ–°æœ€ä½³ fitness
        self.start_epoch = start_epoch  # è®¾ç½®èµ·å§‹è½®æ•°
        if start_epoch > (self.epochs - self.args.close_mosaic):  # å¦‚æœæ¢å¤çš„è½®æ•°å·²ç»è¶…è¿‡å…³é—­ mosaic çš„æ¡ä»¶
            self._close_dataloader_mosaic()  # å…³é—­ mosaic æ•°æ®å¢å¼º

    def _close_dataloader_mosaic(self):
        """å…³é—­æ•°æ®åŠ è½½å™¨ä¸­çš„ Mosaic æ•°æ®å¢å¼ºã€‚"""
        if hasattr(self.train_loader.dataset, "mosaic"):  # å¦‚æœæ•°æ®é›†æ”¯æŒ mosaic å±æ€§
            self.train_loader.dataset.mosaic = False  # ç¦ç”¨ mosaic
        if hasattr(self.train_loader.dataset, "close_mosaic"):  # å¦‚æœæœ‰å…³é—­ mosaic çš„æ–¹æ³•
            LOGGER.info("Closing dataloader mosaic")  # æ‰“å°æ—¥å¿—ä¿¡æ¯
            self.train_loader.dataset.close_mosaic(hyp=copy(self.args))  # æ‰§è¡Œå…³é—­æ“ä½œ

    def build_optimizer(self, model, name="auto", lr=0.001, momentum=0.9, decay=1e-5, iterations=1e5):
        """
        æ ¹æ®æ¨¡å‹æ„å»ºä¼˜åŒ–å™¨ï¼Œå¹¶æ”¯æŒæŒ‡å®šå­¦ä¹ ç‡ã€åŠ¨é‡ã€æƒé‡è¡°å‡ç­‰å‚æ•°ã€‚

        Args:
            model (torch.nn.Module): è¦ä¼˜åŒ–çš„æ¨¡å‹å®ä¾‹ã€‚
            name (str, optional): ä¼˜åŒ–å™¨çš„åç§°ï¼Œæ”¯æŒ 'SGD', 'Adam', 'AdamW' ç­‰ï¼Œé»˜è®¤è‡ªåŠ¨é€‰æ‹©ã€‚
            lr (float, optional): å­¦ä¹ ç‡ï¼Œé»˜è®¤ 0.001ã€‚
            momentum (float, optional): åŠ¨é‡ç³»æ•°ï¼Œé»˜è®¤ 0.9ã€‚
            decay (float, optional): æƒé‡è¡°å‡ç³»æ•°ï¼Œé»˜è®¤ 1e-5ã€‚
            iterations (float, optional): è¿­ä»£æ¬¡æ•°ï¼Œç”¨äºè°ƒæ•´ä¼˜åŒ–å™¨å‚æ•°ï¼Œé»˜è®¤ 1e5ã€‚

        Returns:
            torch.optim.Optimizer: æ„å»ºå¥½çš„ä¼˜åŒ–å™¨å®ä¾‹ã€‚
        """
        g = [], [], []  # å‚æ•°ç»„ï¼šg[0] æœ‰æƒé‡è¡°å‡ï¼Œg[1] æ— æƒé‡è¡°å‡ï¼Œg[2] åç½®å‚æ•°
        bn = tuple(v for k, v in nn.__dict__.items() if "Norm" in k)  # æ ‡å‡†åŒ–å±‚ï¼ˆå¦‚ BatchNorm2dï¼‰
        if name == "auto":  # å¦‚æœä¼˜åŒ–å™¨é€‰æ‹©ä¸ºè‡ªåŠ¨æ¨¡å¼
            LOGGER.info(
                f"{colorstr('optimizer:')} 'optimizer=auto' found, "
                f"ignoring 'lr0={self.args.lr0}' and 'momentum={self.args.momentum}' and "
                f"determining best 'optimizer', 'lr0' and 'momentum' automatically..."
            )
            nc = getattr(model, "nc", 10)  # è·å–æ¨¡å‹çš„ç±»åˆ«æ•°ï¼Œé»˜è®¤ä¸º 10
            lr_fit = round(0.002 * 5 / (4 + nc), 6)  # æ ¹æ®å…¬å¼è‡ªåŠ¨è®¡ç®—å­¦ä¹ ç‡
            name, lr, momentum = ("SGD", 0.01, 0.9) if iterations > 10000 else ("AdamW", lr_fit, 0.9)  # æ ¹æ®è¿­ä»£æ¬¡æ•°é€‰æ‹©ä¼˜åŒ–å™¨
            self.args.warmup_bias_lr = 0.0  # è‹¥ä½¿ç”¨ Adamï¼Œbias çš„ warmup å­¦ä¹ ç‡ä¸è¶…è¿‡ 0.01

        for module_name, module in model.named_modules():  # éå†æ¨¡å‹çš„æ¨¡å—
            for param_name, param in module.named_parameters(recurse=False):  # éå†æ¨¡å—çš„å‚æ•°
                fullname = f"{module_name}.{param_name}" if module_name else param_name  # å®Œæ•´å‚æ•°åç§°
                if "bias" in fullname:  # åç½®å‚æ•°ï¼ˆæ— æƒé‡è¡°å‡ï¼‰
                    g[2].append(param)
                elif isinstance(module, bn):  # æ ‡å‡†åŒ–å±‚æƒé‡ï¼ˆæ— æƒé‡è¡°å‡ï¼‰
                    g[1].append(param)
                else:  # å…¶ä»–å‚æ•°ï¼ˆæœ‰æƒé‡è¡°å‡ï¼‰
                    g[0].append(param)

        optimizers = {"Adam", "Adamax", "AdamW", "NAdam", "RAdam", "RMSProp", "SGD", "auto"}  # æ”¯æŒçš„ä¼˜åŒ–å™¨åˆ—è¡¨
        name = {x.lower(): x for x in optimizers}.get(name.lower())  # æ ‡å‡†åŒ–ä¼˜åŒ–å™¨åç§°
        if name in {"Adam", "Adamax", "AdamW", "NAdam", "RAdam"}:
            optimizer = getattr(optim, name, optim.Adam)(g[2], lr=lr, betas=(momentum, 0.999), weight_decay=0.0)  # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        elif name == "RMSProp":
            optimizer = optim.RMSprop(g[2], lr=lr, momentum=momentum)  # ä½¿ç”¨ RMSProp
        elif name == "SGD":
            optimizer = optim.SGD(g[2], lr=lr, momentum=momentum, nesterov=True)  # ä½¿ç”¨ SGD å¹¶å¯ç”¨ Nesterov åŠ¨é‡
        else:
            raise NotImplementedError(
                f"Optimizer '{name}' not found in list of available optimizers {optimizers}. "
                "Request support for additional optimizers at https://github.com/ultralytics/ultralytics."
            )

        # æ·»åŠ å‚æ•°ç»„åˆ°ä¼˜åŒ–å™¨
        optimizer.add_param_group({"params": g[0], "weight_decay": decay})  # æœ‰æƒé‡è¡°å‡çš„å‚æ•°ç»„
        optimizer.add_param_group({"params": g[1], "weight_decay": 0.0})  # æ— æƒé‡è¡°å‡çš„æƒé‡
        LOGGER.info(
            f"{colorstr('optimizer:')} {type(optimizer).__name__}(lr={lr}, momentum={momentum}) with parameter groups "
            f'{len(g[1])} weight(decay=0.0), {len(g[0])} weight(decay={decay}), {len(g[2])} bias(decay=0.0)'
        )
        return optimizer  # è¿”å›ä¼˜åŒ–å™¨å®ä¾‹
